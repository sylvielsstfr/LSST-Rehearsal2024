{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bf4242-bfc5-4d43-88c4-a8059ae148df",
   "metadata": {},
   "source": [
    "# Convert original Hologram output format (numpy record array) into other dataFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01993b6e-6438-4fca-a5d5-1f9791336847",
   "metadata": {},
   "source": [
    "- author Sylvie Dagoret-Campagne\n",
    "- creation date 2024-09-23\n",
    "- last update : 2024-09-25, version v3\n",
    "- last update : 2024-09-27 : add csv\n",
    "- last update : 2024-09-30 : v4 extended version\n",
    "- affiliation : IJCLab\n",
    "- Kernel @usdf **w_2024_16**\n",
    "- Office emac : mamba_py311\n",
    "- Home emac : base (conda)\n",
    "- laptop : conda_py310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1bc73-a729-4968-8dd6-3abaf8d55287",
   "metadata": {},
   "source": [
    "**Goal** : Notebook to convert the npy format into other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc53afe-c58f-4948-92c9-0090d373ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026d265-2493-4045-afec-26205ff71f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f116e-80e3-46ad-a7db-7f253632e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf752b70-e6ca-4cbf-8e8c-20bf7f0d8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm,SymLogNorm\n",
    "from matplotlib.patches import Circle,Annulus\n",
    "from astropy.visualization import ZScaleInterval\n",
    "props = dict(boxstyle='round', facecolor=\"white\", alpha=0.1)\n",
    "#props = dict(boxstyle='round')\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "import matplotlib.ticker                         # here's where the formatter is\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch,ZScaleInterval,PercentileInterval,\n",
    "                                   ImageNormalize,imshow_norm)\n",
    "from astropy.visualization.stretch import SinhStretch, LinearStretch,AsinhStretch,LogStretch\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "from astropy import constants as c\n",
    "\n",
    "from scipy import interpolate\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.ticker                         # here's where the formatter is\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (4,3)\n",
    "plt.rcParams[\"axes.labelsize\"] = 'xx-large'\n",
    "plt.rcParams['axes.titlesize'] = 'xx-large'\n",
    "plt.rcParams['xtick.labelsize']= 'xx-large'\n",
    "plt.rcParams['ytick.labelsize']= 'xx-large'\n",
    "\n",
    "\n",
    "# new color correction model\n",
    "import pickle\n",
    "\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0d1e6-5f82-4c43-aaa3-8524fc2bc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch,ZScaleInterval,PercentileInterval,\n",
    "                                   ImageNormalize,imshow_norm)\n",
    "from astropy.visualization.stretch import SinhStretch, LinearStretch,AsinhStretch,LogStretch\n",
    "\n",
    "from astropy.time import Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189816c-5048-43ab-a01a-7c078af54489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67327fd4-e405-45ce-8923-cd46ebaa0c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8332dd-24f9-4b19-88f9-c62d0a4aebf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wavelength bin colors\n",
    "#jet = plt.get_cmap('jet')\n",
    "#cNorm = mpl.colors.Normalize(vmin=0, vmax=NSED)\n",
    "#scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "#all_colors = scalarMap.to_rgba(np.arange(NSED), alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13d6a3-7793-4bc0-920a-1d690d9f84b2",
   "metadata": {},
   "source": [
    "### Load Holo fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac0cab-3886-4683-b1c8-fc59edacfd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version_results = \"v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7a644-913e-458a-9b5e-c89447f1d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmfilenamesdict = {\"v1\" : \"data/spectro/auxtel_atmosphere_202301_v3.1.0_doSensorFlat_rebin2_testWithMaskedEdges_newBoundaries_newPolysRescaled_newFitBounds_adjustA1_lockedOrder2_removeThroughputTails_2.npy\",\n",
    "                    \"v2\" : \"auxtel_atmosphere_202301_v3.1.0_doSensorFlat_rebin2_lockedOrder2_FixA1_FixA2_FitAngstrom_FixA1_FixA2_FitAngstrom_WithGaia_freePressure_newThroughput6_BG40Scaled1.09_PeekFinder.npy\",\n",
    "                    \"v3\" : \"u_dagoret_auxtel_atmosphere_202301_v3.1.0_doSensorFlat_rebin2_lockedOrder2_FixA1_FixA2_FitAngstrom_WithGaia_freePressure_newThroughput6_BG40Scaled1.09_AtmoFitPressureA2_SpecErr_PeekFinder_20240924T161119Z.npy\",\n",
    "                    \"v4\" : \"u_dagoret_auxtel_atmosphere_202301_v3.1.0_doSensorFlat_rebin2_lockedOrder2_FixA1_FixA2_FitAngstrom_WithGaia_freePressure_newThroughput6_BG40Scaled1.09_AtmoFitPressureA2_SpecErr_PeekFinder_20240924T161119Z_spectrfullextend.npy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d64220-aecf-4187-89c3-e92198e6c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmfilename = atmfilenamesdict[version_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60336b-f26f-4184-bcdf-e596329ecbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "specdata = np.load(atmfilename,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c7249-f818-4a98-8000-9be75b3c7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec = pd.DataFrame(specdata)\n",
    "df_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5d570-2e92-468b-ab07-63fffd8d2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract the a bug number to have normal dates\n",
    "df_spec[\"nightObs\"] = df_spec.apply(lambda x: x['id']//100_000, axis=1)\n",
    "df_spec[\"nightObs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed10b2-dc4a-49ad-b64e-66e97dfd77dd",
   "metadata": {},
   "source": [
    "## Convert into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28036a0-f5b3-4a9e-b6d2-fa061d96b5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag_HDF5 = True\n",
    "flag_PARQUET = True\n",
    "flag_FITS = True\n",
    "flag_SQL = True\n",
    "flag_CSV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab5c78-a675-45c2-aa4b-b4f87fdfa321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_fn_root = re.findall(\"(.*)[.]npy$\",atmfilename)\n",
    "if len(output_fn_root)>0:\n",
    "    output_fn_root = output_fn_root[0]\n",
    "else:\n",
    "    print(\"error in extracting root for filename {atmfilename}, rootfilename = \",output_fn_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e80b2-1e31-4fa7-b91c-15ad702ed62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_CSV:\n",
    "    output_fn = f\"{output_fn_root}.csv\"\n",
    "    try:\n",
    "        df_spec.to_csv(output_fn)   \n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception type\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)   \n",
    "    finally:\n",
    "        if os.path.exists(output_fn):\n",
    "            print(f\" file {output_fn} created\")\n",
    "        else:\n",
    "            print(f\" >>>>> file {output_fn} NOT created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc5cc7-8920-4e4e-9cba-5423aaa489e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite://', echo=False)\n",
    "\n",
    "if flag_SQL:\n",
    "    output_fn = f\"{output_fn_root}.sql\"\n",
    "    try:\n",
    "        with engine.begin() as connection:\n",
    "            df_spec.to_sql(output_fn,con=connection,if_exists='replace')   \n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception type\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)   \n",
    "    finally:\n",
    "        if os.path.exists(output_fn):\n",
    "            print(f\" file {output_fn} created\")\n",
    "        else:\n",
    "            print(f\" >>>>> file {output_fn} NOT created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52e60f-ed13-4972-b56b-479e81547061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag_HDF5:\n",
    "    output_fn = f\"{output_fn_root}.hdf5\"\n",
    "    try:\n",
    "        df_spec.to_hdf(output_fn,key='data', format='table', data_columns=True)   \n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception type\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)   \n",
    "    finally:\n",
    "        if os.path.exists(output_fn):\n",
    "            print(f\" file {output_fn} created\")\n",
    "        else:\n",
    "            print(f\" >>>>> file {output_fn} NOT created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a3d93-f45e-49ac-b358-e542be32a02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not working with pyarraow then try fastparquet\n",
    "#! pip install fastparquet\n",
    "\n",
    "#import pyarrow.dataset as ds\n",
    "#parquet_format = ds.ParquetFileFormat()\n",
    "#file_options = parquet_format.make_write_options(coerce_timestamps='us', allow_truncated_timestamps=True)\n",
    "\n",
    "\n",
    "if flag_PARQUET:\n",
    "    output_fn = f\"{output_fn_root}.parquet.gzip\"\n",
    "    #output_fn = f\"{output_fn_root}.parquet\"\n",
    "    try:\n",
    "        df_spec.to_parquet(output_fn,compression='gzip',engine='fastparquet')\n",
    "        #ds.write_dataset(df_spec, file_options=file_options,base_dir='./')\n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception type\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)   \n",
    "    finally:\n",
    "        if os.path.exists(output_fn):\n",
    "            print(f\" file {output_fn} created\")\n",
    "        else:\n",
    "            print(f\" >>>>> file {output_fn} NOT created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0215fa-d133-4a1b-84df-cd49322dcf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if flag_FITS:\n",
    "    output_fn = f\"{output_fn_root}.fits\"\n",
    "    t = Table.from_pandas(df_spec)\n",
    "    try:\n",
    "        t.write(output_fn,format=\"fits\",overwrite=True)\n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception type\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst)   \n",
    "    finally:\n",
    "        if os.path.exists(output_fn):\n",
    "            print(f\" file {output_fn} created\")\n",
    "        else:\n",
    "            print(f\" >>>>> file {output_fn} NOT created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892ef1a-076f-4848-aedb-a17645512e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
